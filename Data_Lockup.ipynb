{"cells":[{"attachments":{},"cell_type":"markdown","id":"691dc61e","metadata":{},"source":["# Data 살펴보기위한 곳"]},{"cell_type":"code","execution_count":5,"id":"c2749733","metadata":{},"outputs":[],"source":["import os\n","import json\n","import pandas as pd\n","\n","os.chdir('/root/')\n","\n","PATH = \"./data/\"\n","with open(PATH+'preprocessed_data.json','r') as file:\n","            data = json.load(file)"]},{"cell_type":"code","execution_count":7,"id":"fbbf9d9a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["{'neutral': 6061, 'happy': 5808, 'sad': 6344, 'angry': 6000, 'surprise': 4256, 'fear': 4984, 'disgust': 4513}\n","37966\n"]}],"source":["labels = {}\n","count = 0\n","for item in data['data']:\n","    count += 1\n","    emo_dic = {}\n","    elem_list = []\n","    for emo in item['Emotion']:\n","        emo_dic[emo] = emo_dic.get(emo, 0) + 1\n","    for k, v in emo_dic.items():\n","        elem_list.append([v, k])\n","    elem_list.sort()\n","    top_emo = elem_list.pop()\n","    '''\n","    if elem_list:\n","        if(top_emo[0] == elem_list[-1][0]):\n","            while(elem_list and top_emo[0] == elem_list[-1][0]):\n","                print(top_emo, elem_list[-1])\n","                if (top_emo[1] in ['neutral', 'angry', 'sad']):\n","                    top_emo = elem_list.pop()\n","                else:\n","                    break\n","    '''\n","    #else:\n","     #   labels['only_'+top_emo[1]] = labels.get('only_'+top_emo[1], 0) + 1\n","    \n","    labels[top_emo[1]] = labels.get(top_emo[1], 0) + 1\n","    \n","print(labels)\n","print(count)"]},{"attachments":{},"cell_type":"markdown","id":"8b5a00f6","metadata":{},"source":["# 감정분석 데이터 가져오기 테스트"]},{"cell_type":"code","execution_count":null,"id":"7639069b","metadata":{},"outputs":[],"source":["import pandas as pd\n","import shutil\n","import json\n","import os\n","\n","import numpy as np\n","\n","def GenerateSubDir(PATH, COPYPATH):\n","    # 파일 복사 (현재 경로, 복사할 경로)\n","    def CopyFile(cur_path, COPYPATH):\n","        if not (os.path.isfile(COPYPATH)):\n","            shutil.copy(cur_path, COPYPATH)\n","        \n","    # 재귀적으로 파일 탐색(현재 경로, 복사할 경로, 파일의 태그(종류, wav, EDA ....))\n","    def SearchFiles(path, COPYPATH, tagname):\n","        for cur in os.listdir(path):\n","            cur_path = os.path.join(path, cur)\n","            if os.path.isdir(cur_path):\n","                SearchFiles(cur_path, COPYPATH, tagname)\n","            else:\n","                CopyFile(cur_path, os.path.join(COPYPATH, tagname+'_'+cur))\n","\n","    os.makedirs(COPYPATH, exist_ok=True)\n","    for Ori in [\"감정 분류를 위한 대화 음성 데이터셋\"]:\n","        for cur in os.listdir(os.path.join(PATH, Ori)):\n","            cur_path = os.path.join(PATH, Ori, cur)\n","            if os.path.isdir(cur_path):\n","                SearchFiles(cur_path, COPYPATH, cur)\n","            else:\n","                CopyFile(cur_path, os.path.join(COPYPATH, cur))\n","\n","def Setting_Emotion(series):\n","    encoder = {\n","        'neutral' : 'neutral',\n","        'angry' : 'angry',\n","        'sadness' : 'sad',\n","        'disgust' : 'disgust',\n","        'happiness' : 'happy',\n","        'fear' : 'fear',\n","        'surprise' : 'surprise'\n","    }\n","    data = series.values[3:]\n","    emotions = []\n","\n","    for i in range(0, len(data), 2):\n","        emo = data[i].lower()\n","        emo = encoder[emo]\n","        count = data[i+1]+1\n","        emotions += [emo]*count\n","    return emotions\n","    \n","def Read_DataFrames(COPYPATH, file_name):\n","        df = pd.read_csv(os.path.join(COPYPATH, file_name), encoding=\"cp949\")\n","        df = df[df.columns[:-2]]\n","\n","        emotions = []\n","        wavid = []\n","        for i in range(len(df)):\n","            emotions.append(Setting_Emotion(df.iloc[i]))\n","            wavid.append(file_name[:-4]+ '_' + df['wav_id'].iloc[i]+\".wav\")\n","        df['Emotion'] = emotions\n","        df['wav'] = wavid\n","        df = df[['wav_id', 'wav', '발화문', 'Emotion']]\n","        df.columns = ['file_name', 'wav', 'utterance', 'Emotion']\n","        return df"]},{"cell_type":"code","execution_count":null,"id":"6066b36d","metadata":{},"outputs":[{"ename":"KeyError","evalue":"'data'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[78], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(base_df)):\n\u001b[1;32m     21\u001b[0m     item \u001b[39m=\u001b[39m {key:val \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(base_df\u001b[39m.\u001b[39mcolumns, base_df\u001b[39m.\u001b[39miloc[i]\u001b[39m.\u001b[39mvalues)}\n\u001b[0;32m---> 22\u001b[0m     data[\u001b[39m'\u001b[39;49m\u001b[39mdata\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mappend(item)\n\u001b[1;32m     24\u001b[0m data\n","\u001b[0;31mKeyError\u001b[0m: 'data'"]}],"source":["os.chdir(\"/root/\")\n","#if __name__ == '__main__':\n","# Move All files to one directory\n","PATH = './'\n","COPYPATH = os.path.join(PATH, \"TOTAL\")\n","#GenerateSubDir(PATH, COPYPATH)\n","\n","\n","# 아까 모아놓았던 경로\n","base_df = pd.DataFrame(columns=['file_name', 'wav', 'utterance', 'Emotion'])\n","\n","for file_name in ['4차년도.csv','5차년도.csv', '5차년도_2차.csv']:\n","    df = Read_DataFrames(COPYPATH, file_name)\n","    base_df = pd.concat([base_df, df], axis=0)\n","\n","json_path = os.path.join(PATH, 'data', 'processed_data.json')\n","with open(json_path,'r') as file:\n","    data = json.load(file)\n","\n","for i in range(len(base_df)):\n","    item = {key:val for key, val in zip(base_df.columns, base_df.iloc[i].values)}\n","    data['data'].append(item)\n","\n","data"]},{"cell_type":"code","execution_count":null,"id":"3b22f4e3","metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","id":"b600028d","metadata":{},"source":["# MP4 to wav"]},{"cell_type":"code","execution_count":1,"id":"e614fc1d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["MoviePy - Writing audio in /root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-001.wav\n"]},{"name":"stderr","output_type":"stream","text":["                                                                   \r"]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n","000-001.wav (420713, 2)\n","MoviePy - Writing audio in /root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-002.wav\n"]},{"name":"stderr","output_type":"stream","text":["                                                                   "]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]},{"name":"stdout","output_type":"stream","text":["000-002.wav (375291, 2)\n","MoviePy - Writing audio in /root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-003.wav\n"]},{"name":"stderr","output_type":"stream","text":["                                                                    "]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]},{"name":"stdout","output_type":"stream","text":["000-003.wav (441882, 2)\n","MoviePy - Writing audio in /root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-004.wav\n"]},{"name":"stderr","output_type":"stream","text":["                                                        "]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]},{"name":"stdout","output_type":"stream","text":["000-004.wav (265482, 2)\n","MoviePy - Writing audio in /root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-005.wav\n"]},{"name":"stderr","output_type":"stream","text":["                                                                   "]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"name":"stderr","output_type":"stream","text":["\r"]},{"name":"stdout","output_type":"stream","text":["000-005.wav (397782, 2)\n","MoviePy - Writing audio in /root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-006.wav\n"]},{"name":"stderr","output_type":"stream","text":["                                                                   \r"]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n","000-006.wav (464373, 2)\n","MoviePy - Writing audio in /root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-007.wav\n"]},{"name":"stderr","output_type":"stream","text":["                                                                   \r"]},{"name":"stdout","output_type":"stream","text":["MoviePy - Done.\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmoviepy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meditor\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/root/감정분류용 데이터셋\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 25\u001b[0m M2ts_to_Wav(PATH)\n","Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mM2ts_to_Wav\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     16\u001b[0m cur_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, cur)\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(cur_path):\n\u001b[0;32m---> 18\u001b[0m     M2ts_to_Wav(cur_path)\n\u001b[1;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     ExtractWav(path, cur)\n","Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mM2ts_to_Wav\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     16\u001b[0m cur_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, cur)\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(cur_path):\n\u001b[0;32m---> 18\u001b[0m     M2ts_to_Wav(cur_path)\n\u001b[1;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     ExtractWav(path, cur)\n","Cell \u001b[0;32mIn[1], line 18\u001b[0m, in \u001b[0;36mM2ts_to_Wav\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     16\u001b[0m cur_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, cur)\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(cur_path):\n\u001b[0;32m---> 18\u001b[0m     M2ts_to_Wav(cur_path)\n\u001b[1;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     ExtractWav(path, cur)\n","Cell \u001b[0;32mIn[1], line 20\u001b[0m, in \u001b[0;36mM2ts_to_Wav\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     18\u001b[0m     M2ts_to_Wav(cur_path)\n\u001b[1;32m     19\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     ExtractWav(path, cur)\n","Cell \u001b[0;32mIn[1], line 10\u001b[0m, in \u001b[0;36mExtractWav\u001b[0;34m(path, cur)\u001b[0m\n\u001b[1;32m      7\u001b[0m audio \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39mAudioFileClip(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, cur))\n\u001b[1;32m      8\u001b[0m audio\u001b[39m.\u001b[39mwrite_audiofile(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, file_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m arr \u001b[39m=\u001b[39m audio\u001b[39m.\u001b[39;49mto_soundarray()\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(file_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.wav\u001b[39m\u001b[39m\"\u001b[39m, arr\u001b[39m.\u001b[39mshape)\n","File \u001b[0;32m<decorator-gen-62>:2\u001b[0m, in \u001b[0;36mto_soundarray\u001b[0;34m(self, tt, fps, quantize, nbytes, buffersize)\u001b[0m\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAttribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m\u001b[39m not set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m f(clip, \u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mk)\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/audio/AudioClip.py:113\u001b[0m, in \u001b[0;36mAudioClip.to_soundarray\u001b[0;34m(self, tt, fps, quantize, nbytes, buffersize)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m tt \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mduration \u001b[39m>\u001b[39m max_duration:\n\u001b[0;32m--> 113\u001b[0m         \u001b[39mreturn\u001b[39;00m stacker(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter_chunks(fps\u001b[39m=\u001b[39;49mfps, quantize\u001b[39m=\u001b[39;49mquantize,\n\u001b[1;32m    114\u001b[0m                                         nbytes\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, chunksize\u001b[39m=\u001b[39;49mbuffersize))\n\u001b[1;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m         tt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mduration, \u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39mfps)\n","File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/numpy/core/shape_base.py:279\u001b[0m, in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m overrides\u001b[39m.\u001b[39mARRAY_FUNCTION_ENABLED:\n\u001b[1;32m    277\u001b[0m     \u001b[39m# raise warning if necessary\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     _arrays_for_stack_dispatcher(tup, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 279\u001b[0m arrs \u001b[39m=\u001b[39m atleast_2d(\u001b[39m*\u001b[39;49mtup)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(arrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    281\u001b[0m     arrs \u001b[39m=\u001b[39m [arrs]\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/audio/AudioClip.py:85\u001b[0m, in \u001b[0;36mAudioClip.iter_chunks\u001b[0;34m(self, chunksize, chunk_duration, fps, quantize, nbytes, logger)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[39massert\u001b[39;00m(size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m chunksize)\n\u001b[1;32m     84\u001b[0m tt \u001b[39m=\u001b[39m (\u001b[39m1.0\u001b[39m\u001b[39m/\u001b[39mfps)\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39marange(pospos[i], pospos[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m---> 85\u001b[0m \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_soundarray(tt, nbytes\u001b[39m=\u001b[39;49mnbytes, quantize\u001b[39m=\u001b[39;49mquantize,\n\u001b[1;32m     86\u001b[0m                             fps\u001b[39m=\u001b[39;49mfps, buffersize\u001b[39m=\u001b[39;49mchunksize)\n","File \u001b[0;32m<decorator-gen-62>:2\u001b[0m, in \u001b[0;36mto_soundarray\u001b[0;34m(self, tt, fps, quantize, nbytes, buffersize)\u001b[0m\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/decorators.py:54\u001b[0m, in \u001b[0;36mrequires_duration\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAttribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m\u001b[39m not set\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m f(clip, \u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mk)\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/audio/AudioClip.py:127\u001b[0m, in \u001b[0;36mAudioClip.to_soundarray\u001b[0;34m(self, tt, fps, quantize, nbytes, buffersize)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[39melif len(tt)> 1.5*buffersize:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39m    nchunks = int(len(tt)/buffersize+1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m                      for ttc in tt_chunks])\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39m#print tt.max() - tt.min(), tt.min(), tt.max()\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m snd_array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_frame(tt)\n\u001b[1;32m    129\u001b[0m \u001b[39mif\u001b[39;00m quantize:\n\u001b[1;32m    130\u001b[0m     snd_array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmaximum(\u001b[39m-\u001b[39m\u001b[39m0.99\u001b[39m, np\u001b[39m.\u001b[39mminimum(\u001b[39m0.99\u001b[39m, snd_array))\n","File \u001b[0;32m<decorator-gen-29>:2\u001b[0m, in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/decorators.py:89\u001b[0m, in \u001b[0;36mpreprocess_args.<locals>.wrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     85\u001b[0m new_a \u001b[39m=\u001b[39m [fun(arg) \u001b[39mif\u001b[39;00m (name \u001b[39min\u001b[39;00m varnames) \u001b[39melse\u001b[39;00m arg\n\u001b[1;32m     86\u001b[0m          \u001b[39mfor\u001b[39;00m (arg, name) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(a, names)]\n\u001b[1;32m     87\u001b[0m new_kw \u001b[39m=\u001b[39m {k: fun(v) \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m varnames \u001b[39melse\u001b[39;00m v\n\u001b[1;32m     88\u001b[0m          \u001b[39mfor\u001b[39;00m (k,v) \u001b[39min\u001b[39;00m kw\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m---> 89\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49mnew_a, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kw)\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/Clip.py:93\u001b[0m, in \u001b[0;36mClip.get_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[39mreturn\u001b[39;00m frame\n\u001b[1;32m     92\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_frame(t)\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/audio/io/AudioFileClip.py:77\u001b[0m, in \u001b[0;36mAudioFileClip.__init__.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mduration\n\u001b[1;32m     75\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffersize \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mbuffersize\n\u001b[0;32m---> 77\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_frame \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m t: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreader\u001b[39m.\u001b[39;49mget_frame(t)\n\u001b[1;32m     78\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnchannels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreader\u001b[39m.\u001b[39mnchannels\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/audio/io/readers.py:182\u001b[0m, in \u001b[0;36mFFMPEG_AudioReader.get_frame\u001b[0;34m(self, tt)\u001b[0m\n\u001b[1;32m    177\u001b[0m fr_min, fr_max \u001b[39m=\u001b[39m frames\u001b[39m.\u001b[39mmin(), frames\u001b[39m.\u001b[39mmax()\n\u001b[1;32m    179\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m    180\u001b[0m          (fr_min \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_startframe)\n\u001b[1;32m    181\u001b[0m               \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer)):\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffer_around(fr_min)\n\u001b[1;32m    183\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m\n\u001b[1;32m    184\u001b[0m             (fr_max \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_startframe)\n\u001b[1;32m    185\u001b[0m                  \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer)):\n\u001b[1;32m    186\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_around(fr_max)\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/audio/io/readers.py:244\u001b[0m, in \u001b[0;36mFFMPEG_AudioReader.buffer_around\u001b[0;34m(self, framenumber)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseek(new_bufferstart)\n\u001b[0;32m--> 244\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m=\u001b[39m  \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_chunk(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuffersize)\n\u001b[1;32m    245\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    246\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseek(new_bufferstart)\n","File \u001b[0;32m/usr/local/lib/python3.9/site-packages/moviepy/audio/io/readers.py:113\u001b[0m, in \u001b[0;36mFFMPEG_AudioReader.read_chunk\u001b[0;34m(self, chunksize)\u001b[0m\n\u001b[1;32m    111\u001b[0m chunksize \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(\u001b[39mround\u001b[39m(chunksize))\n\u001b[1;32m    112\u001b[0m L \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnchannels\u001b[39m*\u001b[39mchunksize\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnbytes\n\u001b[0;32m--> 113\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproc\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mread(L)\n\u001b[1;32m    114\u001b[0m dt \u001b[39m=\u001b[39m {\u001b[39m1\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mint8\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m2\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mint16\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m4\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mint32\u001b[39m\u001b[39m'\u001b[39m}[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnbytes]\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(np, \u001b[39m'\u001b[39m\u001b[39mfrombuffer\u001b[39m\u001b[39m'\u001b[39m):\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","\n","def ExtractWav(path, cur):\n","    file_name, ext = os.path.splitext(cur)\n","\n","    if(ext == \".m2ts\"):\n","        audio = mp.AudioFileClip(os.path.join(path, cur))\n","        audio.write_audiofile(os.path.join(path, file_name+\".wav\"))\n","\n","        arr = audio.to_soundarray()\n","    \n","        \n","    # 재귀적으로 파일 탐색(현재 경로, 복사할 경로, 파일의 태그(종류, wav, EDA ....))\n","def M2ts_to_Wav(path):\n","    for cur in os.listdir(path):\n","        cur_path = os.path.join(path, cur)\n","        if os.path.isdir(cur_path):\n","            M2ts_to_Wav(cur_path)\n","        else:\n","            ExtractWav(path, cur)\n","\n","\n","import moviepy.editor as mp\n","PATH = \"/root/감정분류용 데이터셋\"\n","M2ts_to_Wav(PATH)\n"]},{"cell_type":"code","execution_count":null,"id":"a7687516","metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"markdown","id":"f7d19d0f","metadata":{},"source":[]},{"attachments":{},"cell_type":"markdown","id":"2ba91dcb","metadata":{},"source":["# Emotion_classifing"]},{"cell_type":"code","execution_count":14,"id":"d2fd3a5b","metadata":{},"outputs":[{"ename":"SyntaxError","evalue":"invalid syntax (3959262471.py, line 94)","output_type":"error","traceback":["\u001b[0;36m  Cell \u001b[0;32mIn[14], line 94\u001b[0;36m\u001b[0m\n\u001b[0;31m    script_num =\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["import pandas as pd\n","import shutil\n","import json\n","import os\n","\n","import numpy as np\n","\n","def GenerateSubDir(PATH, COPYPATH):\n","    # 파일 복사 (현재 경로, 복사할 경로)\n","    def CopyFile(cur_path, COPYPATH):\n","        if not (os.path.isfile(COPYPATH)):\n","            file_name, ext = os.path.splitext(cur_path)\n","            if(ext == '.csv' or ext == '.wav'):\n","                shutil.copy(cur_path, COPYPATH)\n","        \n","    # 재귀적으로 파일 탐색(현재 경로, 복사할 경로, 파일의 태그(종류, wav, EDA ....))\n","    def SearchFiles(path, COPYPATH, tagname):\n","        for cur in os.listdir(path):\n","            cur_path = os.path.join(path, cur)\n","            if os.path.isdir(cur_path):\n","                SearchFiles(cur_path, COPYPATH, tagname)\n","            else:\n","                CopyFile(cur_path, os.path.join(COPYPATH, tagname+'_'+cur))\n","\n","    os.makedirs(COPYPATH, exist_ok=True)\n","    for Ori in [\"감정분류용 데이터셋\"]:\n","        for cur in os.listdir(os.path.join(PATH, Ori)):\n","            cur_path = os.path.join(PATH, Ori, cur)\n","            if os.path.isdir(cur_path):\n","                SearchFiles(cur_path, COPYPATH, \"감정분류용\")\n","            else:\n","                CopyFile(cur_path, os.path.join(COPYPATH, cur))\n","\n","def Setting_Emotion(series):\n","    encoder = {\n","        'neutral' : 'neutral',\n","        'angry' : 'angry',\n","        'sadness' : 'sad',\n","        'sad' : 'sad',\n","        'disgust' : 'disgust',\n","        'happiness' : 'happy',\n","        'fear' : 'fear',\n","        'surprise' : 'surprise'\n","    }\n","    data = series.values[3:]\n","    emotions = []\n","\n","    for i in range(0, len(data), 2):\n","        emo = data[i].lower()\n","        emo = encoder[emo]\n","        count = data[i+1]+1\n","        emotions += [emo]*count\n","    return emotions\n","    \n","\n","\n","def Read_DataFrames(COPYPATH, file_name):\n","    script_df = pd.read_csv(os.path.join(COPYPATH, file_name), encoding=\"cp949\")\n","    script_df = script_df[script_df.columns[:3]]\n","    script_df['number'] = script_df['number'].apply(int)\n","    script_df = script_df.set_index(keys=['number'])\n","\n","    script_dict = {}\n","    for i in range(len(script_df)):\n","        number = int(script_df['number'].iloc[i])\n","        script = script_df['script'].iloc[i]\n","        emotion = [script_df['emotion'].iloc[i]]\n","        script_dict[number] = {\n","            'script' : script,\n","            'emotion' : emotion\n","        }\n","    \n","    file_names = []\n","    for file in os.listdir(COPYPATH):\n","        file_name, ext = os.path.splitext(file)\n","        if(file_name[:5] == '감정분류용' and ext == '.wav'):\n","            file_names.append(file)\n","    \n","    data = []\n","    for item in file_names:\n","         name, ext = os.path.splitext(item)\n","         script_key = int(name[-3:])\n","         if script_dict.get(script_key, 0):\n","             data.append({\n","                 'wav' : item,\n","                 'file_name' : name,\n","                 'utterance' : script_dict[script_key]['script'],\n","                 'Emotion' : script_dict[script_key]['scriemotionpt']\n","             })\n","    return data"]},{"cell_type":"code","execution_count":13,"id":"089274dd","metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>file_name</th>\n","      <th>wav</th>\n","      <th>utterance</th>\n","      <th>Emotion</th>\n","      <th>number</th>\n","      <th>script</th>\n","      <th>emotion</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>51.0</td>\n","      <td>아이씨. 깜짝이야!.</td>\n","      <td>Surprise</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>52.0</td>\n","      <td>얼마야 이게 다?.</td>\n","      <td>Surprise</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>53.0</td>\n","      <td>저걸 혼자 다 먹어?.</td>\n","      <td>Surprise</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>54.0</td>\n","      <td>왜 이렇게 많이 빠졌지?.</td>\n","      <td>Surprise</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>55.0</td>\n","      <td>8번에 2번 아니야?.</td>\n","      <td>Surprise</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>245</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>346.0</td>\n","      <td>오랜만에 가족들 본다고 얼마나 좋았을 거야.</td>\n","      <td>Sad</td>\n","    </tr>\n","    <tr>\n","      <th>246</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>347.0</td>\n","      <td>이루고 나면 행복할 줄 알았는데 아니더라.</td>\n","      <td>Sad</td>\n","    </tr>\n","    <tr>\n","      <th>247</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>348.0</td>\n","      <td>할아버지는 만나셨어요?.</td>\n","      <td>Sad</td>\n","    </tr>\n","    <tr>\n","      <th>248</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>349.0</td>\n","      <td>화부터 내서 죄송합니다.</td>\n","      <td>Sad</td>\n","    </tr>\n","    <tr>\n","      <th>249</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>350.0</td>\n","      <td>언제까지고 기다릴 수 있어요.</td>\n","      <td>Sad</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>250 rows × 7 columns</p>\n","</div>"],"text/plain":["    file_name  wav utterance Emotion  number                    script  \\\n","0         NaN  NaN       NaN     NaN    51.0               아이씨. 깜짝이야!.   \n","1         NaN  NaN       NaN     NaN    52.0                얼마야 이게 다?.   \n","2         NaN  NaN       NaN     NaN    53.0              저걸 혼자 다 먹어?.   \n","3         NaN  NaN       NaN     NaN    54.0            왜 이렇게 많이 빠졌지?.   \n","4         NaN  NaN       NaN     NaN    55.0              8번에 2번 아니야?.   \n","..        ...  ...       ...     ...     ...                       ...   \n","245       NaN  NaN       NaN     NaN   346.0  오랜만에 가족들 본다고 얼마나 좋았을 거야.   \n","246       NaN  NaN       NaN     NaN   347.0   이루고 나면 행복할 줄 알았는데 아니더라.   \n","247       NaN  NaN       NaN     NaN   348.0             할아버지는 만나셨어요?.   \n","248       NaN  NaN       NaN     NaN   349.0             화부터 내서 죄송합니다.   \n","249       NaN  NaN       NaN     NaN   350.0          언제까지고 기다릴 수 있어요.   \n","\n","      emotion  \n","0    Surprise  \n","1    Surprise  \n","2    Surprise  \n","3    Surprise  \n","4    Surprise  \n","..        ...  \n","245       Sad  \n","246       Sad  \n","247       Sad  \n","248       Sad  \n","249       Sad  \n","\n","[250 rows x 7 columns]"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["os.chdir(\"/root/\")\n","#if __name__ == '__main__':\n","# Move All files to one directory\n","PATH = './'\n","COPYPATH = os.path.join(PATH, \"TOTAL\")\n","#GenerateSubDir(PATH, COPYPATH)\n","\n","\n","# 아까 모아놓았던 경로\n","data = pd.DataFrame(columns=['file_name', 'wav', 'utterance', 'Emotion'])\n","\n","for file_name in ['스크립트.csv']:\n","    df = Read_DataFrames(COPYPATH, file_name)\n","    base_df = pd.concat([base_df, df], axis=0)\n","\n","base_df"]},{"cell_type":"code","execution_count":null,"id":"dc087d53","metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","id":"488f1cc2","metadata":{},"source":["# Audio check"]},{"cell_type":"code","execution_count":27,"id":"1cec8dd2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/root\n","True\n"]},{"data":{"text/plain":["2"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["\n","\n","\n","import soundfile as sf\n","import os\n","os.chdir('/root/')\n","print(os.getcwd())\n","print(os.path.isfile('./TOTAL/감정분류용_000-001.wav'))\n","wav, _ = sf.read('./TOTAL/감정분류용_000-001.wav')\n","wav.shape[1]"]},{"cell_type":"code","execution_count":31,"id":"a8a74bc7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(841426,)\n"]}],"source":["def ExtractWav(path):\n","    sound  = mp.AudioFileClip(path)\n","    return sound\n","\n","import soundfile as sf\n","import moviepy.editor as mp\n","PATH = \"/root/감정분류용 데이터셋/0~9_감정분류_데이터셋/000/movie/000-001.wav\"\n","#PATH = \"/root/TOTAL/4차년도_5e4942578849ac3aacea545b.wav\"\n","sound = ExtractWav(PATH)\n","arr = sound.to_soundarray(nbytes=1)\n","wav, _ = sf.read(PATH)\n","wav = wav.reshape((1, -1))\n","wav = wav.squeeze()\n","\n","print(wav.shape)\n","#sound.write_audiofile(\"/root/test.wav\", nbytes=1)\n"]},{"cell_type":"code","execution_count":34,"id":"11debc22","metadata":{},"outputs":[{"data":{"text/plain":["array([1, 2, 3, 4, 5, 6])"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","np.array([[1,2],[3,4],[5,6]]).reshape((1, -1)).squeeze()"]},{"cell_type":"code","execution_count":25,"id":"711f8aa2","metadata":{},"outputs":[{"data":{"text/plain":["(348160,)"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["import soundfile as sf\n","wav, _ = sf.read(\"/root/TOTAL/4차년도_5e4942578849ac3aacea545b.wav\")\n","wav.shape"]},{"cell_type":"code","execution_count":11,"id":"90bc72e0","metadata":{},"outputs":[{"data":{"text/plain":["(348160,)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["wav.shape"]},{"cell_type":"code","execution_count":12,"id":"4169dcab","metadata":{},"outputs":[{"data":{"text/plain":["0.0"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["wav[0]"]},{"cell_type":"code","execution_count":null,"id":"cf3d66ac","metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","id":"5b1ed3be","metadata":{},"source":["# "]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"19Pj3KZwNmna0-GHE21zka1MEdm5eVBBk","timestamp":1681100970615}],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1c7005471e974aceb86f45130b5b5a56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c470ad56d074bac9eb4b38d55f6cb5d","placeholder":"​","style":"IPY_MODEL_80fe2791fc94470f836ce051cef381a2","value":" 360M/360M [00:04&lt;00:00, 88.4MB/s]"}},"7006293ca5b6464aa77e3b54973eb4fe":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"704b60a6d18149ccae353a1ad7042824":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7717a8e3004e43cab97371d10de20b57":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_92b3aa5cae894ced8b4a95ac156f3b96","max":377664473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_704b60a6d18149ccae353a1ad7042824","value":377664473}},"7ecec5b31bb7420b84af147424981556":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80fe2791fc94470f836ce051cef381a2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fdbf8547ae746ffbe0ba34d559955f1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_de282c36d9c04f5ebc69e0d8e0b31d77","IPY_MODEL_7717a8e3004e43cab97371d10de20b57","IPY_MODEL_1c7005471e974aceb86f45130b5b5a56"],"layout":"IPY_MODEL_7006293ca5b6464aa77e3b54973eb4fe"}},"92b3aa5cae894ced8b4a95ac156f3b96":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c470ad56d074bac9eb4b38d55f6cb5d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c367e4fe32da422091faff75a2cae63f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de282c36d9c04f5ebc69e0d8e0b31d77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ecec5b31bb7420b84af147424981556","placeholder":"​","style":"IPY_MODEL_c367e4fe32da422091faff75a2cae63f","value":"100%"}}}}},"nbformat":4,"nbformat_minor":5}
